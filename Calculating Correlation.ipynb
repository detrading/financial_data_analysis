{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master File\n",
    "\n",
    "**Calculating Correlation for Coca-Cola**\n",
    "\n",
    "In this file, you will find all the functions from the Google Trends Data & Stock Analysis files as well as our calculations to obtain the correlation coefficient. We intentionally left out any extensive descriptions of the functions from this notebook to keep it uncluttered. If you would like to see our theory behind these functions, more in-depth explanations, and test cases, please visit our other two notebooks.\n",
    "\n",
    "At the bottom of the file, we will be using these functions to calcuate the correlation between our stock returns and trends data for n-lags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import all necessary packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lxml\n",
    "import requests\n",
    "import requests_cache\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "# for plotting & manipulating datetimes\n",
    "from matplotlib.dates import date2num       \n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib import mlab as mlab\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime as DT\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "requests_cache.install_cache(\"cache\")\n",
    "#%matplotlib inline # only for python 3\n",
    "\n",
    "# required info\n",
    "google_username = \"***@gmail.com\"\n",
    "google_password = \"***\"\n",
    "\n",
    "# Login to Google. Only need to run this once, the rest of requests will use the same session.\n",
    "pytrend = TrendReq(google_username, google_password, custom_useragent=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All necessary functions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Goolge Trends Data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to quickly change the search term list into a list of lists\n",
    "def listit(t):\n",
    "    term_listed = []\n",
    "    term_listed.append(t)\n",
    "    return term_listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to get each company's data frame separately - includes past 3 years and categories\n",
    "def get_term_df2(term, cat_num):\n",
    "    pytrend.build_payload(kw_list = term, cat = cat_num, geo = 'US', timeframe = '2014-01-05 2017-03-11')\n",
    "    new_df = pytrend.interest_over_time()\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to obtain correlation coefficient for n-lags\n",
    "def calc_corr(n_lag):\n",
    "    if n_lag == 0:\n",
    "        return result.corr(l)\n",
    "    else:\n",
    "        r = result.iloc[n_lag:]\n",
    "        t = l.iloc[:-n_lag]\n",
    "        if len(r) == len(t):\n",
    "            return r.corr(t)\n",
    "        else:\n",
    "            print \"Not same length\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Stock Analysis file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to get historical stock data from Yahoo Finance\n",
    "def getYahooFinanceStockData(stock = '^GSPC', fromMonth = '01', fromDay = '01', fromYear = '1960'):\n",
    "    #build the url and read the full contents as a string (going back in time upto start of specified year)\n",
    "    url = 'http://ichart.finance.yahoo.com/table.csv?s=' + stock + '&a=' + fromMonth + '&b=' + fromDay + '&c=' + fromYear\n",
    "    fulltext = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "  \n",
    "    #split the fulltext into individual lines based on the newline character\n",
    "    fulltextlines = fulltext.splitlines()\n",
    "\n",
    "    #split the lines into headers and an array of data, based by comma characters\n",
    "    header = fulltextlines[0].split(',')    #for now, fine to just discard the header...\n",
    "    data = np.array([line.split(',') for line in fulltextlines[1:]])\n",
    "  \n",
    "    #note, if you wanted to return reported closing values instead of adjusted closing values, use column data[4] instead of data[6].\n",
    "    adjustedClosingPrices = data[:,6].astype(np.float)  #convert it to an array of floats instead of strings.\n",
    "    ##adjustedClosingPrices = np.array(list(map(float, data[:,6])))\n",
    "    ##adjustedClosingPrices = data[:,6]\n",
    "    closing_dates = data[:,0]\n",
    "  \n",
    "    return closing_dates, adjustedClosingPrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calcualtes the lognormal return from a specified stock over n days\n",
    "def calcLogNormalStockReturns(stockPrices = np.empty(0), n_days=1):   \n",
    "    n_day_lognormal_returns = np.empty(len(stockPrices) - n_days)\n",
    "    # n-day training return; use \"-n\" to omit oldest n days that won't have a pair with which to compare\n",
    "    for i in range(len(stockPrices) - n_days):      \n",
    "        n_day_lognormal_returns[i] = np.log(float(stockPrices[i]) / float(stockPrices[i+n_days]))\n",
    "  \n",
    "    return n_day_lognormal_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calcualtes the percent return from a specified stock over n days\n",
    "def calcPercentStockReturns(stockPrices = np.empty(0), n_days=1):\n",
    "    n_day_percent_returns = np.empty(len(stockPrices) - n_days)\n",
    "    \n",
    "    # n-day training return; use \"-n\" to omit oldest n days that won't have a pair with which to compare\n",
    "    for i in range(len(stockPrices) - n_days):\n",
    "        n_day_percent_returns[i] = (float(stockPrices[i]) - float(stockPrices[i+n_days])) / float(stockPrices[i+n_days]) *100\n",
    "  \n",
    "    return n_day_percent_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert avg returns per week & reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take a time series of stock returns and return a binary time series identifying some percent of worst returns in that period\n",
    "def worstReturns(stock_returns = np.empty(0), pWorst = 5):\n",
    "    worst_ones = np.zeros(len(stock_returns), dtype=int)\n",
    "    p = np.percentile(stock_returns, pWorst)  #identify all values less than this.\n",
    "    for i in range(len(stock_returns)):\n",
    "        if stock_returns[i] <= p: worst_ones[i] = 1\n",
    "    \n",
    "    return worst_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Correlation:**\n",
    "\n",
    "Now we have reached the exciting part where we actually test our code with the Coca-Cola company to calculate the correlation between stock returns and search trends data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### CODE TESTING WITH COCA-COLA #####\n",
    "\n",
    "stocks=['KO'] # can add more stocks if wanted\n",
    "n_days = 5\n",
    "month = '1'\n",
    "day = '1'\n",
    "year = '2014'\n",
    "\n",
    "print('\\nTest results for stock PERCENT returns (similar, less likely to be used):')\n",
    "for stock in stocks:  \n",
    "    closing_dates, stock_prices = getYahooFinanceStockData(stock, month, day, year)\n",
    "    stock_returns = calcPercentStockReturns(stock_prices, n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get binomial df\n",
    "\n",
    "bottom5Mask = worstReturns(stock_returns, 5)\n",
    "bottom5Returns = np.array([r for r, mask in zip(stock_returns, bottom5Mask) if mask == 1])\n",
    "bottom5Dates = np.array([d for d, mask in zip(closing_dates, bottom5Mask) if mask == 1])\n",
    "print('number of zero or one flags for worst 5% of returns:', len(bottom5Mask))\n",
    "print('number of returns in the bottom 5% (where mask == 1):', len(bottom5Returns))\n",
    "print('number of dates corresponding to the bottom 5% (where mask == 1):', len(bottom5Dates), '\\n')\n",
    "\n",
    "# Plot it...\n",
    "pltdata = []\n",
    "for i in range(len(bottom5Returns)):\n",
    "    pltdata.append((DT.datetime.strptime(bottom5Dates[i], \"%Y-%m-%d\"), bottom5Returns[i]))\n",
    "x = [date2num(date) for (date, value) in pltdata]\n",
    "y = [value for (date, value) in pltdata]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x,y, 'ro')\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%d %b %Y')) #('%b %d %Y'))\n",
    "ax.xaxis_date()  #tell matplotlib to interpret the x-axis values as dates\n",
    "plt.gcf().autofmt_xdate(rotation=45) #rotate the x labels\n",
    "plt.title('Bottom 5% of returns')\n",
    "plt.ylabel('returns')\n",
    "plt.xlabel('dates prior to the present')\n",
    "plt.show()\n",
    "\n",
    "# Display it...\n",
    "print('Here are the 5% worst returns from the dataset:')\n",
    "for i in range(len(bottom5Returns)): print(bottom5Dates[i], '\\t', bottom5Returns[i])\n",
    "print('\\nHere is the start of the binary bitmask that identifyies the locations of those worst returns:')\n",
    "for i in range(min(len(bottom5Mask), 50)): print(bottom5Mask[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
